---
title: "Untitled"
author: "Zhao Yuedian"
date: "2021/6/19"
output: html_document
---

```{r}
library(xgboost)
library(caret)
library(readxl)
library(dplyr)
library(tidyverse)
library(Metrics)
library(data.table)
```


```{r}
my_data_4 <- read_excel("my_data_dummies.xlsx")
```


```{r}
my_data_4$DyestuffUsage <- as.numeric(my_data_4$DyestuffUsage)
num_cols = c("Pre_Art_Actual_Time", "Dye_Art_Actual_Time", "Dye_Art_Sample_Time", "After_Art_Actual_Time", "After_Art_Sample_Time", "Fix_Art_Actual_Time", "Fix_Art_Sample_Time", "DyestuffUsage", "Dyeing_Ratio","Dye_weight","pure_dye","pure_after","pure_fix")
for (col in num_cols) set(my_data_4, which(is.na(my_data_4[[col]])), col, 0)
```

```{r}
set.seed(123)
indices <- sample(1:nrow(my_data_4), size = 0.95 * nrow(my_data_4))
train <- as.matrix(my_data_4[indices,])
test <- as.matrix(my_data_4[-indices,])
```

### S1



```{r}
s1_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 224],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 5,
    eta = .26
  )
```

```{r}
s1_pred_xgb_1 <- predict(s1_xgb_tuned, test[, 2:223])
s1_pred_xgb_1_trn <- predict(s1_xgb_tuned, train[, 2:223])


s1_yhat_1 <- s1_pred_xgb_1
s1_y <- test[, 224]
postResample(s1_yhat_1, s1_y)

s1_r_1 <- s1_y - s1_yhat_1
hist(s1_r_1)
# RMSE   Rsquared        MAE 
#32.7715385  0.8574526 17.7707422 
```

### S2

```{r}
s2_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 225],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 3,
    eta = .34
  )
```

```{r}
s2_pred_xgb_1 <- predict(s2_xgb_tuned, test[, 2:223])
s2_pred_xgb_1_trn <- predict(s2_xgb_tuned, train[, 2:223])
s2_yhat_1 <- s2_pred_xgb_1
s2_y <- test[, 225]
postResample(s2_yhat_1, s2_y)

s2_r_1 <- s2_y - s2_yhat_1
hist(s2_r_1)

#        RMSE   Rsquared        MAE 
#  20.9703086  0.9531763  9.9694447 
```


### S3

```{r}
s3_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 226],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 3,
    eta = .24
  )
```

```{r}
s3_pred_xgb_1 <- predict(s3_xgb_tuned, test[, 2:223])
s3_pred_xgb_1_trn <- predict(s3_xgb_tuned, train[, 2:223])
s3_yhat_1 <- s3_pred_xgb_1
s3_y <- test[, 226]
postResample(s3_yhat_1, s3_y)

s3_r_1 <- s3_y - s3_yhat_1
hist(s3_r_1)

#  RMSE   Rsquared        MAE 
#50.2929970  0.2517556 30.3931830  
```


### S4

```{r}
s4_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 227],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 5,
    eta = .22
  )
```

```{r}
s4_pred_xgb_1 <- predict(s4_xgb_tuned, test[, 2:223])
s4_pred_xgb_1_trn <- predict(s4_xgb_tuned, train[, 2:223])
s4_yhat_1 <- s4_pred_xgb_1
s4_y <- test[, 227]
postResample(s4_yhat_1, s4_y)

s4_r_1 <- s4_y - s4_yhat_1
hist(s4_r_1)

# RMSE   Rsquared        MAE 
#32.8016773  0.8325974 18.4864625 

```

### s5

```{r}
s5_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 228],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 5,
    eta = .31
  )
```

```{r}
s5_pred_xgb_1 <- predict(s5_xgb_tuned, test[, 2:223])
s5_pred_xgb_1_trn <- predict(s5_xgb_tuned, train[, 2:223])
s5_yhat_1 <- s5_pred_xgb_1
s5_y <- test[, 228]
postResample(s5_yhat_1, s5_y)

s5_r_1 <- s5_y - s5_yhat_1
hist(s5_r_1)

# RMSE   Rsquared        MAE 
# 27.3126545  0.1463923 11.6825439 

```

### s6

```{r}
s6_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 229],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 3,
    eta = .27  )
```

```{r}
s6_pred_xgb_1 <- predict(s6_xgb_tuned, test[, 2:223])
s6_pred_xgb_1_trn <- predict(s6_xgb_tuned, train[, 2:223])
s6_yhat_1 <- s6_pred_xgb_1
s6_y <- test[, 229]
postResample(s6_yhat_1, s6_y)

s6_r_1 <- s6_y - s6_yhat_1
hist(s6_r_1)

# RMSE   Rsquared        MAE 
# 31.6222741  0.5096121 17.0977407 

```
### s7

```{r}
s7_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 230],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 2,
    eta = .23
  )
```

```{r}
s7_pred_xgb_1 <- predict(s7_xgb_tuned, test[, 2:223])
s7_pred_xgb_1_trn <- predict(s7_xgb_tuned, train[, 2:223])
s7_yhat_1 <- s7_pred_xgb_1
s7_y <- test[, 230]
postResample(s7_yhat_1, s7_y)

s7_r_1 <- s7_y - s7_yhat_1
hist(s7_r_1)

# RMSE   Rsquared        MAE 
# 64.4737689  0.5658917 31.0570007 

```

### s8

```{r}
s8_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 231] - train[,232],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 4,
    eta = .33
  )
```

```{r}
s8_pred_xgb_1 <- predict(s8_xgb_tuned, test[, 2:223])
s8_pred_xgb_1_trn <- predict(s8_xgb_tuned, train[, 2:223])
s8_yhat_1 <- s8_pred_xgb_1
s8_y <- train[, 231] - train[, 232]
postResample(s8_yhat_1, s8_y)

s8_r_1 <- s8_y - s8_yhat_1
hist(s8_r_1)

# RMSE   Rsquared        MAE 
# 64.4737689  0.5658917 31.0570007 

```

```{r}
pred_xgb_total <- s1_pred_xgb_1 + s2_pred_xgb_1 + s3_pred_xgb_1 + s4_pred_xgb_1 + s5_pred_xgb_1 + s6_pred_xgb_1 + s7_pred_xgb_1 + s8_pred_xgb_1

pred_xgb_total_trn <- s1_pred_xgb_1_trn + s2_pred_xgb_1_trn + s3_pred_xgb_1_trn + s4_pred_xgb_1_trn + s5_pred_xgb_1_trn + s6_pred_xgb_1_trn + s7_pred_xgb_1_trn + s8_pred_xgb_1_trn
```

```{r}
#write.csv(pred_xgb_total,'xgb8steps_output.csv')
```


```{r}
residuals_xgb <- test[,231] - pred_xgb_total
residuals_xgb_trn <- train[,231] - pred_xgb_total_trn
quantile(residuals_xgb,  probs = c(10,25,75,90)/100)
```

```{r}
sqrt(sum(residuals_xgb^2)/length(residuals_xgb))
sqrt(sum(residuals_xgb_trn^2)/length(residuals_xgb_trn))
```


```{r}
new_res_xgb <- residuals_xgb - mean(residuals_xgb)
print("90mins:")
length(new_res_xgb[new_res_xgb<90&new_res_xgb>-90])/length(new_res_xgb)
print("30mins:")
length(new_res_xgb[new_res_xgb<30&new_res_xgb>-30])/length(new_res_xgb)
```

### Whole

```{r}
whole_xgb <-
  xgboost(
    data = train[, 2:223],
    label = train[, 231],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 6,
    eta = .25
  )
```

```{r}
whole_pred_xgb <- predict(whole_xgb, test[, 2:223])
whole_yhat <- whole_pred_xgb
whole_y <- test[, 231]
postResample(whole_yhat, whole_y)

whole_r <- whole_y - whole_yhat
hist(whole_r)

#  RMSE    Rsquared         MAE 
#111.6642199   0.8747199  81.6256648 
```

```{r}
#grid search
#create hyperparameter grid
hyper_grid <- expand.grid(max_depth = seq(2, 5, 1),
                          eta = seq(.2, .35, .01))
whole_xgb_train_rmse <- NULL
whole_xgb_test_rmse <- NULL

for (j in 1:64) {
  set.seed(123)
  whole_xgb_untuned <- xgb.cv(
    data = train[, 2:223],
    label = train[, 231],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    nfold = 5,
    max_depth = hyper_grid$max_depth[j],
    eta = hyper_grid$eta[j]
  )
  
  whole_xgb_train_rmse[j] <- whole_xgb_untuned$evaluation_log$train_rmse_mean[whole_xgb_untuned$best_iteration]
  whole_xgb_test_rmse[j] <- whole_xgb_untuned$evaluation_log$test_rmse_mean[whole_xgb_untuned$best_iteration]
  
  cat(j, "\n")
}

#ideal hyperparamters
hyper_grid[which.min(whole_xgb_test_rmse), ]
```

```{r}
whole_xgb_tuned <-
  xgboost(
    data = train[, 2:223],
    label = train[, 231],
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 3,
    eta = .2
  )
```

```{r}
whole_pred_xgb_1 <- predict(whole_xgb_tuned, test[, 2:223])

whole_yhat_1 <- whole_pred_xgb_1
whole_y <- test[, 231]
postResample(whole_yhat_1, whole_y)

whole_r_1 <- whole_y - whole_yhat_1

hist(whole_r_1)

# RMSE    Rsquared         MAE 
# 105.5434858   0.8862732  76.3714203 
new_whole_r_1 <- whole_r_1 - mean(whole_r_1)
length(new_whole_r_1[new_whole_r_1<90&new_whole_r_1>-90])/length(new_whole_r_1)
length(new_whole_r_1[new_whole_r_1<60&new_whole_r_1>-60])/length(new_whole_r_1)
length(new_whole_r_1[new_whole_r_1<30&new_whole_r_1>-30])/length(new_whole_r_1)
quantile(whole_r_1,  probs = c(10,25,75,90)/100)
```
```{r}
whole_r_log <- log(whole_y) - log(whole_yhat_1)
##write.csv(whole_r_log,'xgb_log_redisuals.csv')
```





